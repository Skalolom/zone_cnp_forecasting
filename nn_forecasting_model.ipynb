{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 666\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, datetime, timedelta\n",
    "import os\n",
    "import logging\n",
    "import urllib.parse as url\n",
    "import warnings\n",
    "import numpy as np\n",
    "from pytorch_forecasting import TimeSeriesDataSet, DeepAR, TemporalFusionTransformer, LogNormalDistributionLoss, NHiTS, MAE\n",
    "from pytorch_forecasting.data.encoders import EncoderNormalizer\n",
    "from typing import Union, Dict, Optional, Tuple\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pl.seed_everything(666)\n",
    "\n",
    "class ForecastingModel:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            history_start_date: Union[date, datetime],\n",
    "            history_end_date: Union[date, datetime],\n",
    "            forecast_end_date: Union[date, datetime],\n",
    "            target_data: Dict[str, list],\n",
    "            exog_data: Dict[str, list],\n",
    "            target_data_interval: str = 'hour',\n",
    "            exog_data_interval: str = 'hour',\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        This method initializes training, validation and testing datasets for training our model.\n",
    "        :param history_start_date: starting date of our training dataset\n",
    "        :param history_end_date: ending date of our training dataset / starting date of our testing dataset\n",
    "        :param forecast_end_date: ending date of our testing dataset\n",
    "        :param target_data: dictionary contained series names and corresponding column names for target data\n",
    "        :param exog_data: dictionary contained series names and corresponding column names for exogenous data\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        First we fetch data from syspower\n",
    "        \"\"\"\n",
    "        self._dates = {\n",
    "            'history_start_date': history_start_date,\n",
    "            'history_end_date': history_end_date,\n",
    "            'forecast_end_date': forecast_end_date\n",
    "        }\n",
    "        self._target_data = self.get_data(data_dict=target_data, interval=target_data_interval)\n",
    "        self._decoder_length = 0\n",
    "        self._encoder_length = 0\n",
    "\n",
    "        temp_date = forecast_end_date + timedelta(days=1)\n",
    "        exog_data_df = self.get_data(data_dict=exog_data, interval=exog_data_interval, end_date=temp_date)\n",
    "\n",
    "        exog_data_df['ds'] = pd.to_datetime(exog_data_df['ds'])\n",
    "        exog_data_df = exog_data_df.set_index('ds').resample('H').interpolate()\n",
    "        exog_data_df = exog_data_df.reset_index()\n",
    "        self._exog_data = exog_data_df.loc[exog_data_df['ds'] < temp_date, :]\n",
    "        self._full_data = pd.merge(left=self._target_data, right=self._exog_data, on='ds', how='left')\n",
    "        self._train_dataloader, self._val_dataloader, self._result_df = self.create_dataloaders(\n",
    "            target_column_names=target_data.get('column_names', ''),\n",
    "            exog_column_names=exog_data.get('column_names', '')\n",
    "        )\n",
    "        self._networks = ()\n",
    "        self._trainers = ()\n",
    "        self._fitted_networks = []\n",
    "\n",
    "\n",
    "    @property\n",
    "    def target_data(self):\n",
    "        return self._target_data\n",
    "\n",
    "    @property\n",
    "    def exog_data(self):\n",
    "        return self._exog_data\n",
    "\n",
    "    @property\n",
    "    def dates(self):\n",
    "        return self._dates\n",
    "\n",
    "    @property\n",
    "    def train_dataloader(self):\n",
    "        return self._train_dataloader\n",
    "\n",
    "    @property\n",
    "    def val_dataloader(self):\n",
    "        return self._val_dataloader\n",
    "\n",
    "    @property\n",
    "    def result_df(self):\n",
    "        return self._result_df\n",
    "\n",
    "    @property\n",
    "    def networks(self):\n",
    "        return self._networks\n",
    "\n",
    "    @property\n",
    "    def trainers(self):\n",
    "        return self._trainers\n",
    "\n",
    "    @property\n",
    "    def fitted_networks(self):\n",
    "        return self._fitted_networks\n",
    "\n",
    "    @property\n",
    "    def encoder_length(self):\n",
    "        return self._encoder_length\n",
    "\n",
    "    @property\n",
    "    def decoder_length(self):\n",
    "        return self._decoder_length\n",
    "\n",
    "    def get_data(\n",
    "            self,\n",
    "            data_dict: Dict[str, list],\n",
    "            end_date: Optional[datetime] = None,\n",
    "            interval: str = 'hour'\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        This method loads data from syspower\n",
    "        :param data_dict: dictionary with series names and corresponding column names\n",
    "        :param end_date: date where data should ends\n",
    "        :param interval: string that defines time interval on which data should be fetched\n",
    "        :return: dataframe with the loaded data\n",
    "        \"\"\"\n",
    "        if end_date:\n",
    "            request = {\n",
    "                \"series\": ','.join(data_dict.get('data_series')),\n",
    "                'interval': interval,\n",
    "                'start': self.dates.get('history_start_date').strftime('%Y-%m-%d'),\n",
    "                'end': end_date.strftime('%Y-%m-%d'),\n",
    "                'token': '8ycj3jSf2DJZOtX',\n",
    "                'emptydata': 'yes',\n",
    "                'currency': '',\n",
    "                'dateFormat': 'nbno',\n",
    "                'numberFormat': 'nothousandsdot',\n",
    "                'fileformat': 'csv',\n",
    "                'headers': 'no'\n",
    "            }\n",
    "        else:\n",
    "            request = {\n",
    "                \"series\": ','.join(data_dict.get('data_series')),\n",
    "                'interval': interval,\n",
    "                'start': self.dates.get('history_start_date').strftime('%Y-%m-%d'),\n",
    "                'end': self.dates.get('forecast_end_date').strftime('%Y-%m-%d'),\n",
    "                'token': '8ycj3jSf2DJZOtX',\n",
    "                'emptydata': 'yes',\n",
    "                'currency': '',\n",
    "                'dateFormat': 'nbno',\n",
    "                'numberFormat': 'nothousandsdot',\n",
    "                'fileformat': 'csv',\n",
    "                'headers': 'no'\n",
    "            }\n",
    "\n",
    "        data_url = f'https://syspower5.skm.no/api/webquery/execute?{url.urlencode(request)}'\n",
    "        data = pd.read_csv(\n",
    "            data_url,\n",
    "            sep=';',\n",
    "            index_col=0,\n",
    "            parse_dates=True,\n",
    "            dayfirst=True,\n",
    "            header=None,\n",
    "            names = ['ds'] + data_dict.get('column_names', [])\n",
    "        ).interpolate().reset_index()\n",
    "        return data\n",
    "\n",
    "    def create_dataloaders(\n",
    "            self,\n",
    "            target_column_names: list,\n",
    "            exog_column_names: list,\n",
    "            encoder_length: int = 168,\n",
    "            decoder_length: int = 24\n",
    "    ) -> Tuple[DataLoader, DataLoader, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        This method creates datasets and dataloaders in a format expected by pytorch_forecasting.\n",
    "\n",
    "        :param target_column_names: list with names of columns of target values.\n",
    "        :param exog_column_names: list with names of columns of exogenous values\n",
    "        :param encoder_length: number of hours on which we base forecast\n",
    "        :param decoder_length: number of hours for which we forecast ahead\n",
    "        :return tuple of shape (train_dataloader, val_dataloader)\n",
    "        \"\"\"\n",
    "        result = self._full_data.melt(\n",
    "            id_vars=['ds'],\n",
    "            value_vars=target_column_names\n",
    "        )\n",
    "        groups_dict = {key: value for value, key in enumerate(target_column_names)}\n",
    "        time_idx = np.tile(np.arange(self._full_data.shape[0]), len(target_column_names))\n",
    "        result['time_idx'] = time_idx\n",
    "        result['group'] = result.apply(lambda x: groups_dict.get(x['variable'], 0), axis=1)\n",
    "\n",
    "        result['date'] = result.apply(lambda x: pd.to_datetime(x['ds'].date()), axis=1)\n",
    "        result['country'] = result.apply(lambda x: x['variable'].split('_')[-1][:2], axis=1)\n",
    "\n",
    "        special_days = pd.read_excel('syspower_dict.xlsx', 'calendar')\n",
    "        special_days.columns = ['date', 'country', 'spec_day']\n",
    "        special_days['country'] = special_days.apply(lambda x: x['country'].lower(), axis=1)\n",
    "        special_days['spec_day'] = special_days['spec_day'] + 1\n",
    "        result['weekday'] = result.apply(lambda x: x['ds'].weekday(), axis=1)\n",
    "\n",
    "        result = pd.merge(left=result, right=special_days, on=['date', 'country'], how='left').fillna(value=0).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        result['day_type'] = result.apply(\n",
    "            lambda x: 'holiday' if (x['weekday'] == 5 or x['weekday'] == 6 or x['spec_day'] != 0) else 'common',\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        result['hour'] = result.apply(lambda x: x['ds'].hour, axis=1).astype(str).astype('category')\n",
    "        result['weekday'] = result['weekday'].astype(str).astype('category')\n",
    "        result['month'] = result.apply(lambda x: x['ds'].month, axis=1).astype(str).astype('category')\n",
    "        result['spec_day'] = result['spec_day'].astype(str).astype('category')\n",
    "\n",
    "        df_list = [self.exog_data] * len(target_data.get('column_names', ''))\n",
    "        df = pd.concat(df_list, ignore_index=True).drop(columns='ds')\n",
    "        result = pd.concat([result, df], axis=1)\n",
    "        train_data = result[lambda x: x['ds'] < history_end_date]\n",
    "\n",
    "        training_cutoff = train_data['time_idx'].max() - decoder_length\n",
    "        training_dataset = TimeSeriesDataSet(\n",
    "            train_data[lambda x: x.time_idx <= training_cutoff],\n",
    "            group_ids=['group'],\n",
    "            target='value',\n",
    "            time_idx='time_idx',\n",
    "            min_encoder_length=encoder_length,\n",
    "            max_encoder_length=encoder_length,\n",
    "            min_prediction_length=decoder_length,\n",
    "            max_prediction_length=decoder_length,\n",
    "            time_varying_unknown_reals=['value'],\n",
    "            time_varying_known_reals=exog_column_names,\n",
    "            time_varying_known_categoricals=['day_type', 'country'],\n",
    "            target_normalizer=EncoderNormalizer(transformation='log'),\n",
    "            #add_relative_time_idx=True,\n",
    "            add_target_scales=True,\n",
    "            add_encoder_length=True\n",
    "        )\n",
    "        validation_dataset = TimeSeriesDataSet.from_dataset(\n",
    "            training_dataset,\n",
    "            train_data,\n",
    "            predict=True\n",
    "        )\n",
    "\n",
    "        batch_size = 64\n",
    "        train_dataloader = training_dataset.to_dataloader(\n",
    "            train=True,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=0\n",
    "        )\n",
    "        val_dataloader = validation_dataset.to_dataloader(\n",
    "            train=False,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=0\n",
    "        )\n",
    "\n",
    "        self._encoder_length = encoder_length\n",
    "        self._decoder_length = decoder_length\n",
    "\n",
    "        return train_dataloader, val_dataloader, result\n",
    "\n",
    "    def add_networks(\n",
    "            self,\n",
    "            nn_hyperparameters: Dict[str, Dict[str, Union[int, float]]],\n",
    "            tr_hyperparameters: Dict[str, Dict[str, Union[int, float]]],\n",
    "            optimize: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This method adds desired number of different neural networks to forecasting model\n",
    "\n",
    "        :param nn_hyperparameters: dictionary with desired values of hyperparameters for each neural network\n",
    "        :param tr_hyperparameters: dictionary with hyperparamteres for trainers\n",
    "        :param optimize: argument defines if automatic optimization fo hyperparameters needed. If False (default) hyperparameters defined by nn_hyperparameters and\n",
    "        default parameters of related networks. If True, then parameters are defined by optuna\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        for nn_name in nn_hyperparameters:\n",
    "            nn_params = nn_hyperparameters.get(nn_name)\n",
    "            tr_params = tr_hyperparameters.get(nn_name)\n",
    "            if nn_name == 'deepar':\n",
    "                current_nn = DeepAR.from_dataset(\n",
    "                    self.train_dataloader.dataset,\n",
    "                    **nn_params\n",
    "                )\n",
    "            if nn_name == 'tft':\n",
    "                current_nn = TemporalFusionTransformer.from_dataset(\n",
    "                    self.train_dataloader.dataset,\n",
    "                    **nn_params\n",
    "                )\n",
    "            if nn_name == 'nhits':\n",
    "                current_nn = NHiTS.from_dataset(\n",
    "                    self.train_dataloader.dataset,\n",
    "                    **nn_params\n",
    "                )\n",
    "            current_trainer = pl.Trainer(**tr_params)\n",
    "            self._networks += (current_nn, )\n",
    "            self._trainers += (current_trainer, )\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        This method fits networks in self.networks with respective trainers from self.trainers\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for index, network in enumerate(self.networks):\n",
    "            self.trainers[index].fit(\n",
    "                network,\n",
    "                train_dataloaders=self.train_dataloader,\n",
    "                val_dataloaders=self.val_dataloader\n",
    "            )\n",
    "            if network.__class__ == DeepAR:\n",
    "                self._fitted_networks += [DeepAR.load_from_checkpoint(self.trainers[index].checkpoint_callback.best_model_path)]\n",
    "            if network.__class__ == TemporalFusionTransformer:\n",
    "                self._fitted_networks += [TemporalFusionTransformer.load_from_checkpoint(self.trainers[index].checkpoint_callback.best_model_path)]\n",
    "            if network.__class__ == NHiTS:\n",
    "                self._fitted_networks += [NHiTS.load_from_checkpoint(self.trainers[index].checkpoint_callback.best_model_path)]\n",
    "\n",
    "    def predict(self):\n",
    "        final_prediction = np.array([])\n",
    "        current_prediction = np.array([])\n",
    "\n",
    "        self.target_data['cnp_fi_pred'] = 0\n",
    "        dates_range = pd.date_range(\n",
    "            start=self.dates.get('history_end_date') + timedelta(hours=self.decoder_length),\n",
    "            end=self.dates.get('forecast_end_date'),\n",
    "            freq='D'\n",
    "        )\n",
    "        for current_date in dates_range:\n",
    "            final_prediction = np.array([])\n",
    "            for fitted_network in self.fitted_networks:\n",
    "                cur_df = self.result_df.loc[\n",
    "                         (self.result_df['ds'] >= current_date - timedelta(hours=self.encoder_length+self.decoder_length)) &\n",
    "                         (self.result_df['ds'] < current_date),\n",
    "                         :\n",
    "                         ]\n",
    "                current_prediction = fitted_network.predict(\n",
    "                    cur_df,\n",
    "                    mode='prediction',\n",
    "                    return_x=False\n",
    "                )\n",
    "                current_prediction = current_prediction.detach().numpy()[-1, :]\n",
    "                if not final_prediction.size:\n",
    "                    final_prediction = current_prediction\n",
    "                else:\n",
    "                    final_prediction += current_prediction\n",
    "            self.target_data.loc[\n",
    "                (self.target_data['ds'] >= current_date - timedelta(days=1)) &\n",
    "                (self.target_data['ds'] < current_date),\n",
    "                'cnp_fi_pred'\n",
    "            ] = final_prediction / len(self.fitted_networks)\n",
    "\n",
    "        forecast_results = self.target_data.loc[\n",
    "            (self.target_data['ds'] >= history_end_date) &\n",
    "            (self.target_data['ds'] < forecast_end_date),\n",
    "            ['ds', 'cnp_fi', 'cnp_fi_pred']\n",
    "        ].set_index('ds')\n",
    "        forecast_results.plot(figsize=(16, 6))\n",
    "\n",
    "        mae = mean_absolute_error(\n",
    "            y_true=forecast_results.loc[:, 'cnp_fi'],\n",
    "            y_pred=forecast_results.loc[:, 'cnp_fi_pred']\n",
    "        )\n",
    "        print(f'MAE = {mae}')\n",
    "\n",
    "        forecast_results.reset_index(inplace=True)\n",
    "        forecast_results['day'] = forecast_results.apply(lambda x: x['ds'].day, axis=1)\n",
    "        forecast_results['hour'] = forecast_results.apply(lambda x: x['ds'].hour, axis=1)\n",
    "        forecast_results['diff'] = forecast_results.apply(lambda x: np.abs(x['cnp_fi'] - x['cnp_fi_pred']), axis=1)\n",
    "        diff = forecast_results.groupby(by='day').max()['diff'].to_numpy()\n",
    "        print(f'max deviation = {np.mean(diff * 1000)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "target_data = {\n",
    "    'data_series': [\n",
    "        'CNPNP',\n",
    "        'CNPSE', 'CNPSE1', 'CNPSE2', 'CNPSE3', 'CNPSE4',\n",
    "        'CNPNO', 'CNPNO1', 'CNPNO2', 'CNPNO3', 'CNPNO4', 'CNPNO5',\n",
    "        'CNPDEN', 'CNPDK1', 'CNPDK2',\n",
    "        'CNPEE', 'CNPLV', 'CNPLT',\n",
    "        'CNPDE', 'CNPNL', 'CNPUK',\n",
    "        'CNPFI'\n",
    "    ],\n",
    "    'column_names': [\n",
    "        'cnp_np',\n",
    "        'cnp_se', 'cnp_se1', 'cnp_se2', 'cnp_se3', 'cnp_se4',\n",
    "        'cnp_no', 'cnp_no1', 'cnp_no2', 'cnp_no3', 'cnp_no4', 'cnp_no5',\n",
    "        'cnp_dk', 'cnp_dk1', 'cnp_dk2',\n",
    "        'cnp_ee', 'cnp_lv', 'cnp_lt',\n",
    "        'cnp_de', 'cnp_nl', 'cnp_uk',\n",
    "        'cnp_fi'\n",
    "    ]\n",
    "}\n",
    "\n",
    "exog_data = {\n",
    "    'data_series': ['SMHITEMPFI_F', 'SMHITEMPSE_F', 'SMHITEMPNO_F', 'SMHITEMPNP_F', 'SMHITEMPDK_F'],\n",
    "    'column_names': ['temp_fi', 'temp_se', 'temp_no', 'temp_np', 'temp_dk']\n",
    "}\n",
    "\n",
    "history_start_date = datetime(year=2020, month=12, day=1)\n",
    "history_end_date = datetime(year=2021, month=12, day=5)\n",
    "forecast_end_date = datetime(year=2021, month=12, day=12)\n",
    "\n",
    "forecasting_model = ForecastingModel(\n",
    "    history_start_date=history_start_date,\n",
    "    history_end_date=history_end_date,\n",
    "    forecast_end_date=forecast_end_date,\n",
    "    target_data=target_data,\n",
    "    exog_data=exog_data,\n",
    "    target_data_interval='hour',\n",
    "    exog_data_interval='day'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "deepar:\n",
    "the best params = {'gradient_clip_val': 0.436058692807735, 'hidden_size': 155, 'rnn_layers': 2, 'learning_rate': 0.00997853051614353}; the best value = -1.2212425470352173\n",
    "\n",
    "tft:\n",
    "{'gradient_clip_val': 0.27155203157679625, 'hidden_size': 75, 'dropout': 0.2193904175901326, 'hidden_continuous_size': 43, 'attention_head_size': 5,\n",
    " 'learning_rate': 0.0012277693365326608}\n",
    "\"\"\"\n",
    "\n",
    "nn_hyperparameters = {\n",
    "    'deepar': {\n",
    "        'hidden_size': 40,\n",
    "        'rnn_layers': 3,\n",
    "        'learning_rate': 1e-3,\n",
    "        'cell_type': 'GRU',\n",
    "        'loss': LogNormalDistributionLoss()\n",
    "    },\n",
    "    'tft': {\n",
    "        'hidden_size': 128,\n",
    "        'dropout': 0.219,\n",
    "        'hidden_continuous_size': 32,\n",
    "        'attention_head_size': 6,\n",
    "        'learning_rate': 5e-3\n",
    "    },\n",
    "    'nhits': {\n",
    "        'hidden_size': 1024,\n",
    "        'learning_rate': 1e-3,\n",
    "        'pooling_sizes': [16, 8, 1],\n",
    "        'dropout': 0.1,\n",
    "        'loss': MAE(),\n",
    "        'reduce_on_plateau_patience': 5\n",
    "    }\n",
    "}\n",
    "\n",
    "early_stop_callback_deepar = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-4,\n",
    "    patience=10,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "early_stop_callback_tft = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-4,\n",
    "    patience=10,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "early_stop_callback_nhits = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-4,\n",
    "    patience=10,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "tr_hyperparameters = {\n",
    "    'deepar': {\n",
    "        'max_epochs': 100,\n",
    "        'min_epochs': 50,\n",
    "        'gpus': [0] if torch.cuda.is_available() else None,\n",
    "        'callbacks': [early_stop_callback_deepar],\n",
    "        'limit_train_batches': 40,\n",
    "        'limit_val_batches': 10,\n",
    "        'gradient_clip_val': 0.25\n",
    "    },\n",
    "    'tft': {\n",
    "        'max_epochs': 10,\n",
    "        'gpus': [0] if torch.cuda.is_available() else None,\n",
    "        'callbacks': [early_stop_callback_tft],\n",
    "        'limit_train_batches': 40,\n",
    "        'limit_val_batches': 10,\n",
    "        'gradient_clip_val': 0.25\n",
    "    },\n",
    "    'nhits': {\n",
    "        'max_epochs': 100,\n",
    "        'min_epochs': 50,\n",
    "        'gpus': [0] if torch.cuda.is_available() else None,\n",
    "        'callbacks': [early_stop_callback_nhits],\n",
    "        'limit_train_batches': 40,\n",
    "        'limit_val_batches': 10,\n",
    "        'gradient_clip_val': 0.25\n",
    "    }\n",
    "}\n",
    "forecasting_model.add_networks(nn_hyperparameters=nn_hyperparameters, tr_hyperparameters=tr_hyperparameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                   | Type                      | Params\n",
      "---------------------------------------------------------------------\n",
      "0 | loss                   | LogNormalDistributionLoss | 0     \n",
      "1 | logging_metrics        | ModuleList                | 0     \n",
      "2 | embeddings             | MultiEmbedding            | 319   \n",
      "3 | rnn                    | LSTM                      | 310 K \n",
      "4 | distribution_projector | Linear                    | 312   \n",
      "---------------------------------------------------------------------\n",
      "310 K     Trainable params\n",
      "0         Non-trainable params\n",
      "310 K     Total params\n",
      "1.243     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f588c6a77e7b42cba976788f75527b9e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 666\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22afa155c39549f08f1dc19179d8f7bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3fd2de6b3b1499899895a13124744a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "481773f078b6466282ace8e8391ce132"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14e17ceb05ba4f1889facd1f734a3ccb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b52742b45d8d4c44b6279d13e864ce4b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9501dfae988945e38f248d2613a2643f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2238551755284e85a5c699968b33fd47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c858f55c0774ce0aadc071c76b2f455"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d17fa0a87bac47b8b63aa4c1a79ddb5c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df3c1ce950e34e6fb48cb1d0a81d3274"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2037450b72be40e1bd837e7eb3da307c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4aaaf52fb03b4ca5baf583f7fb2bdf31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fffc20020b3d450694ac04953184f7b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "114ed5079ec64b8393da3522b29e8558"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "329d6a970e7b49af88ec4eff18bd5ac4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7dac1284223d412bb57d306dd52d1a21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "671c5493bf4e4de8bbf913a0f1f7ab63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d39958129b814cac9f6426602ca1bf8c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93a23bb1b3dd4766880eaab622d21cd0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3dbc0c2b931a45d7a65363d83d154253"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eae6a12bbf1940faa14b14dd9b87f0ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d83498b6f6f9453b917417c943e63147"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b6653440953454e98c791385a64cfec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69665cbddf294324bcbe000c3d366478"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6da61800fe414b63918963b73352f5b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "554f42b836ab4648b340fc5ee1bb41d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "096192f22070451ab597a6af4ca012d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c5125f4266f4492b0f79f731711937b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "677047cfd2674e32bd5bff4daffef200"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c38a11458da4066bf09beef175eb6f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c2d9d1214b54d779efc7a15413b03aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3756a32d41ef4d4da802ba912597fccf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f63312085213482daefa33d58181b49a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30531ac6ef3e44b8b33a15780126a980"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6258613ed93a432297dfdb07a3cb4f48"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/home/bathory/DataspellProjects/ZoneCnpForecast'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIsADirectoryError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_2947612/2171760940.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mforecasting_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_2947612/3846399551.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    307\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fitted_networks\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mDeepAR\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_from_checkpoint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainers\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcheckpoint_callback\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_model_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    308\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mnetwork\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mTemporalFusionTransformer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 309\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fitted_networks\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mTemporalFusionTransformer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_from_checkpoint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainers\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcheckpoint_callback\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_model_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    310\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    311\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/pytorch_lightning/core/saving.py\u001B[0m in \u001B[0;36mload_from_checkpoint\u001B[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[1;32m    132\u001B[0m                 \u001B[0mcheckpoint\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpl_load\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcheckpoint_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmap_location\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    133\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 134\u001B[0;31m                 \u001B[0mcheckpoint\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpl_load\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcheckpoint_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mstorage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloc\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstorage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    135\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    136\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mhparams_file\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(path_or_url, map_location)\u001B[0m\n\u001B[1;32m     35\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhub\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict_from_url\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath_or_url\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmap_location\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m     \u001B[0mfs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_filesystem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath_or_url\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 37\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0mfs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath_or_url\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     38\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmap_location\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/fsspec/spec.py\u001B[0m in \u001B[0;36mopen\u001B[0;34m(self, path, mode, block_size, cache_options, **kwargs)\u001B[0m\n\u001B[1;32m   1004\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1005\u001B[0m             \u001B[0mac\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"autocommit\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_intrans\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1006\u001B[0;31m             f = self._open(\n\u001B[0m\u001B[1;32m   1007\u001B[0m                 \u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1008\u001B[0m                 \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/fsspec/implementations/local.py\u001B[0m in \u001B[0;36m_open\u001B[0;34m(self, path, mode, block_size, **kwargs)\u001B[0m\n\u001B[1;32m    153\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_mkdir\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m\"w\"\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    154\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmakedirs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_parent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexist_ok\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 155\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mLocalFileOpener\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    156\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mtouch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/fsspec/implementations/local.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001B[0m\n\u001B[1;32m    248\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompression\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_compression\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcompression\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    249\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mblocksize\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDEFAULT_BUFFER_SIZE\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 250\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    251\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    252\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/fsspec/implementations/local.py\u001B[0m in \u001B[0;36m_open\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    253\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclosed\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    254\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautocommit\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0;34m\"w\"\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 255\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    256\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompression\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    257\u001B[0m                     \u001B[0mcompress\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompr\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompression\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIsADirectoryError\u001B[0m: [Errno 21] Is a directory: '/home/bathory/DataspellProjects/ZoneCnpForecast'"
     ]
    }
   ],
   "source": [
    "forecasting_model.fit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forecasting_model.predict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}